\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bottou(1991)]{bo91}
L.~Bottou.
\newblock Stochastic gradient learning in neural networks.
\newblock \emph{Neuro-N\^imes}, 1991.

\bibitem[Chaudhari and Soatto(2018)]{ch18}
P.~Chaudhari and S.~Soatto.
\newblock Sgd performs variational inference, converges to limit cycles for
  deep networks.
\newblock \emph{ICLR}, 2018.

\bibitem[Dixon and Ward(2018)]{di18}
M.F. Dixon and T.~Ward.
\newblock Takeuchi information as a form of regularization.
\newblock \emph{Arxiv Preprint}, 2018.

\bibitem[Dyer and Gur-Ari(2019)]{dy19}
E.~Dyer and G.~Gur-Ari.
\newblock Asymptotics of wide networks from feynman diagrams.
\newblock \emph{ICML Workshop}, 2019.

\bibitem[Goyal et~al.(2018)Goyal, Doll\'{a}r, Girshick, Noordhuis, Wesolowski,
  Kyrola, Tulloch, Jia, and He]{go18}
P.~Goyal, P.~Doll\'{a}r, R.~Girshick, P.~Noordhuis, L.~Wesolowski, A.~Kyrola,
  A.~Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd.
\newblock \emph{Data @ Scale}, 2018.

\bibitem[Li et~al.(2017)Li, Tai, and E]{li17}
Qianxiao Li, Cheng Tai, and Weinan E.
\newblock Stochastic modified equations and adaptive stochastic gradient
  algorithms i.
\newblock \emph{PMLR}, 2017.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Tomioka, Salakhutdinov, and
  Srebro]{ne17b}
B.~Neyshabur, R.~Tomioka, R.~Salakhutdinov, and N.~Srebro.
\newblock Geometry of optimization and implicit regularization in deep
  learning.
\newblock \emph{Chapter 4 from Intel CRI-CI: Why and When Deep Learning Works
  Compendium}, 2017.

\bibitem[Roberts(2018)]{ro18}
D.A. Roberts.
\newblock Sgd implicitly regularizes generalization error.
\newblock \emph{NeurIPS: Integration of Deep Learning Theories Workshop}, 2018.

\bibitem[Wei and Schwab(2019)]{we19b}
Mingwei Wei and D.J. Schwab.
\newblock How noise affects the hessian spectrum in overparameterized neural
  networks.
\newblock \emph{Arxiv Preprint}, 2019.

\bibitem[Yaida(2019)]{ya19a}
Sho Yaida.
\newblock Fluctuation-dissipation relations for sgd.
\newblock \emph{ICLR}, 2019.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and Vinyals]{zh17}
Chiyuan Zhang, S.~Bengio, M.~Hardt, B.~Recht, and O.~Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock \emph{ICLR}, 2017.

\end{thebibliography}
