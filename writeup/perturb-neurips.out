\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Example of diagram-based computation of SGD's test loss}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Background, notation, and assumptions}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Related work}{section.1}% 4
\BOOKMARK [1][-]{section.2}{Theory, specialized to E=B=1 SGD's test loss}{}% 5
\BOOKMARK [2][-]{subsection.2.1}{Main result}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.2}{SGD descends on a C-smoothed landscape and prefers minima flat w.r.t. C.}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.3}{Both flat and sharp minima overfit less}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.4}{High-C regions repel small-\(E,B\) SGD more than large-\(E,B\) SGD}{section.2}% 9
\BOOKMARK [2][-]{subsection.2.5}{Non-Gaussian noise affects SGD but not SDE}{section.2}% 10
\BOOKMARK [1][-]{section.3}{Experiments}{}% 11
\BOOKMARK [2][-]{subsection.3.1}{Training time, epochs, and batch size; C repels SGD more than GD}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.2}{Minima that are flat with respect to C attract SGD}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.3}{Sharp and flat minima both overfit less than medium minima}{section.3}% 14
\BOOKMARK [1][-]{section.4}{Conclusion: implications for practice}{}% 15
\BOOKMARK [1][-]{section.1}{How to calculate test losses}{}% 16
\BOOKMARK [2][-]{subsection.1.1}{An example calculation: the effect of epochs}{section.1}% 17
\BOOKMARK [3][-]{subsubsection.1.1.1}{Space-time grids}{subsection.1.1}% 18
\BOOKMARK [3][-]{subsubsection.1.1.2}{Embeddings of diagrams into space-time}{subsection.1.1}% 19
\BOOKMARK [3][-]{subsubsection.1.1.3}{Values of the embeddings}{subsection.1.1}% 20
\BOOKMARK [3][-]{subsubsection.1.1.4}{Sum of the values}{subsection.1.1}% 21
\BOOKMARK [2][-]{subsection.1.2}{How to identify the relevant space-time}{section.1}% 22
\BOOKMARK [2][-]{subsection.1.3}{How to identify the relevant diagram embeddings}{section.1}% 23
\BOOKMARK [2][-]{subsection.1.4}{How to evaluate each embedding}{section.1}% 24
\BOOKMARK [3][-]{subsubsection.1.4.1}{Un-resummed values: uvalue\(D\)}{subsection.1.4}% 25
\BOOKMARK [3][-]{subsubsection.1.4.2}{Resummed values: rvaluef\(D\)}{subsection.1.4}% 26
\BOOKMARK [3][-]{subsubsection.1.4.3}{Overall}{subsection.1.4}% 27
\BOOKMARK [2][-]{subsection.1.5}{How to sum the embeddings' values}{section.1}% 28
\BOOKMARK [2][-]{subsection.1.6}{Interpreting diagrams intuitively}{section.1}% 29
\BOOKMARK [2][-]{subsection.1.7}{How to solve variant problems}{section.1}% 30
\BOOKMARK [2][-]{subsection.1.8}{Do diagrams streamline computation?}{section.1}% 31
\BOOKMARK [3][-]{subsubsection.1.8.1}{Effect of batch size}{subsection.1.8}% 32
\BOOKMARK [3][-]{subsubsection.1.8.2}{Effect of non-Gaussian noise at a minimum.}{subsection.1.8}% 33
\BOOKMARK [1][-]{section.2}{Mathematics of the theory}{}% 34
\BOOKMARK [2][-]{subsection.2.1}{Assumptions and Definitions}{section.2}% 35
\BOOKMARK [2][-]{subsection.2.2}{A key lemma \340 la Dyson}{section.2}% 36
\BOOKMARK [2][-]{subsection.2.3}{From Dyson to diagrams}{section.2}% 37
\BOOKMARK [2][-]{subsection.2.4}{Interlude: a review of M\366bius inversion}{section.2}% 38
\BOOKMARK [2][-]{subsection.2.5}{Theorems 1 and 2}{section.2}% 39
\BOOKMARK [2][-]{subsection.2.6}{Proofs of corollaries}{section.2}% 40
\BOOKMARK [3][-]{subsubsection.2.6.1}{Corollary 1}{subsection.2.6}% 41
\BOOKMARK [3][-]{subsubsection.2.6.2}{Corollary 2's first part}{subsection.2.6}% 42
\BOOKMARK [3][-]{subsubsection.2.6.3}{Corollary 2's second part}{subsection.2.6}% 43
\BOOKMARK [3][-]{subsubsection.2.6.4}{Corollaries 4 and 3}{subsection.2.6}% 44
\BOOKMARK [3][-]{subsubsection.2.6.5}{Corollary 5}{subsection.2.6}% 45
\BOOKMARK [2][-]{subsection.2.7}{Future topics}{section.2}% 46
\BOOKMARK [1][-]{section.3}{Experimental methods}{}% 47
\BOOKMARK [2][-]{subsection.3.1}{What artificial landscapes did we use?}{section.3}% 48
\BOOKMARK [3][-]{subsubsection.3.1.1}{Gauss}{subsection.3.1}% 49
\BOOKMARK [3][-]{subsubsection.3.1.2}{Archimedes}{subsection.3.1}% 50
\BOOKMARK [3][-]{subsubsection.3.1.3}{Mean Estimation}{subsection.3.1}% 51
\BOOKMARK [2][-]{subsection.3.2}{What image-classification landscapes did we use?}{section.3}% 52
\BOOKMARK [3][-]{subsubsection.3.2.1}{Architectures}{subsection.3.2}% 53
\BOOKMARK [3][-]{subsubsection.3.2.2}{Datasets}{subsection.3.2}% 54
\BOOKMARK [2][-]{subsection.3.3}{Measurement process}{section.3}% 55
\BOOKMARK [3][-]{subsubsection.3.3.1}{Diagram evaluation on real landscapes}{subsection.3.3}% 56
\BOOKMARK [3][-]{subsubsection.3.3.2}{Descent simulations}{subsection.3.3}% 57
\BOOKMARK [2][-]{subsection.3.4}{Implementing optimizers}{section.3}% 58
\BOOKMARK [2][-]{subsection.3.5}{Software frameworks and hardware}{section.3}% 59
\BOOKMARK [2][-]{subsection.3.6}{Unbiased estimators of landscape statistics}{section.3}% 60
\BOOKMARK [2][-]{subsection.3.7}{Additional figures}{section.3}% 61
