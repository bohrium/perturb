\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Example of diagram-based computation of SGD's test loss}{section.1}% 2
\BOOKMARK [2][-]{subsection.1.2}{Background, notation, and assumptions}{section.1}% 3
\BOOKMARK [2][-]{subsection.1.3}{Related work}{section.1}% 4
\BOOKMARK [1][-]{section.2}{Theory, specialized to E=B=1 SGD's test loss}{}% 5
\BOOKMARK [2][-]{subsection.2.1}{Main result}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.2}{Insights from the formalism}{section.2}% 7
\BOOKMARK [3][-]{subsubsection.2.2.1}{SGD descends on a C-smoothed landscape and prefers minima flat w.r.t. C.}{subsection.2.2}% 8
\BOOKMARK [3][-]{subsubsection.2.2.2}{Both flat and sharp minima overfit less}{subsection.2.2}% 9
\BOOKMARK [3][-]{subsubsection.2.2.3}{High-C regions repel small-\(E,B\) SGD more than large-\(E,B\) SGD}{subsection.2.2}% 10
\BOOKMARK [3][-]{subsubsection.2.2.4}{Non-Gaussian noise affects SGD but not SDE}{subsection.2.2}% 11
\BOOKMARK [1][-]{section.3}{Experiments}{}% 12
\BOOKMARK [2][-]{subsection.3.1}{Training time, epochs, and batch size; C repels SGD more than GD}{section.3}% 13
\BOOKMARK [2][-]{subsection.3.2}{Minima that are flat with respect to C attract SGD}{section.3}% 14
\BOOKMARK [2][-]{subsection.3.3}{Sharp and flat minima both overfit less than medium minima}{section.3}% 15
\BOOKMARK [1][-]{section.4}{Conclusion: implications for practice}{}% 16
\BOOKMARK [1][-]{section.1}{How to calculate test losses: a practical guide}{}% 17
\BOOKMARK [2][-]{subsection.1.1}{An example calculation}{section.1}% 18
\BOOKMARK [2][-]{subsection.1.2}{How to identify the relevant space-time}{section.1}% 19
\BOOKMARK [2][-]{subsection.1.3}{How to identify the relevant diagram embeddings}{section.1}% 20
\BOOKMARK [2][-]{subsection.1.4}{How to evaluate each embedding}{section.1}% 21
\BOOKMARK [2][-]{subsection.1.5}{How to sum the embeddings' values}{section.1}% 22
\BOOKMARK [2][-]{subsection.1.6}{Interpreting diagrams to build intuition}{section.1}% 23
\BOOKMARK [2][-]{subsection.1.7}{How to solve variant problems}{section.1}% 24
\BOOKMARK [2][-]{subsection.1.8}{Do diagrams streamline computation?}{section.1}% 25
\BOOKMARK [1][-]{section.2}{Mathematics of the theory}{}% 26
\BOOKMARK [2][-]{subsection.2.1}{Assumptions and definitions}{section.2}% 27
\BOOKMARK [2][-]{subsection.2.2}{A key lemma \340 la Dyson}{section.2}% 28
\BOOKMARK [2][-]{subsection.2.3}{From Dyson to diagrams}{section.2}% 29
\BOOKMARK [2][-]{subsection.2.4}{Interlude: a review of M\366bius inversion}{section.2}% 30
\BOOKMARK [2][-]{subsection.2.5}{Theorems 1 and 2}{section.2}% 31
\BOOKMARK [2][-]{subsection.2.6}{How to modify proofs to handle variants}{section.2}% 32
\BOOKMARK [2][-]{subsection.2.7}{Proofs of corollaries}{section.2}% 33
\BOOKMARK [3][-]{subsubsection.2.7.1}{Corollary 1}{subsection.2.7}% 34
\BOOKMARK [3][-]{subsubsection.2.7.2}{Corollary 2's first part}{subsection.2.7}% 35
\BOOKMARK [3][-]{subsubsection.2.7.3}{Corollary 2's second part}{subsection.2.7}% 36
\BOOKMARK [3][-]{subsubsection.2.7.4}{Corollaries 4 and 3}{subsection.2.7}% 37
\BOOKMARK [3][-]{subsubsection.2.7.5}{Corollary 5}{subsection.2.7}% 38
\BOOKMARK [2][-]{subsection.2.8}{Future topics}{section.2}% 39
\BOOKMARK [1][-]{section.3}{Experimental methods}{}% 40
\BOOKMARK [2][-]{subsection.3.1}{What artificial landscapes did we use?}{section.3}% 41
\BOOKMARK [2][-]{subsection.3.2}{What image-classification landscapes did we use?}{section.3}% 42
\BOOKMARK [2][-]{subsection.3.3}{Measurement process}{section.3}% 43
\BOOKMARK [2][-]{subsection.3.4}{Implementing optimizers}{section.3}% 44
\BOOKMARK [2][-]{subsection.3.5}{Software frameworks and hardware}{section.3}% 45
\BOOKMARK [2][-]{subsection.3.6}{Unbiased estimators of landscape statistics}{section.3}% 46
\BOOKMARK [2][-]{subsection.3.7}{Additional figures}{section.3}% 47
