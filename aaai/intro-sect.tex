  Gradient estimates, measured on minibatches and thus noisy, form the primary
learning signal when training deep neural nets.  While users of deep learning
benefit from the intuition that \emph{stochastic gradient descent} (SGD)
approximates deterministic descent (GD) \citep{bo91,le15}, SGD's gradient noise
alters training dynamics and testing losses \citep{go18,wu20}.
%
The implicit regularization of SGD on finite training data is of particular
interest.  The learning signal reflects that data's finitude in two
ways: updates in different epochs are correlated and the gradient estimated on
each batch has a skewed distribution.
%
%Correlations between updates in different epochs and severely skewed gradient
%noise directly result from the finitude of the training set and thus relate to
%generalization.  
%
However, current models of SGD dynamics such as stochastic differential
equations (SDE) assume independent Gaussian noise.
%
By contrast, we analyze SGD dynamics with correlated, non-Gaussian on short
timescales or near minima.  We apply our theory to find that \textbf{gradient
noise biases learning} toward low-curvature, low-noise regions of the loss
landscape.

  Specifically, we study \emph{the expectation over training sets of the
testing loss after $T$ updates} by Taylor expanding that loss in the learning
rate $\eta$.  While the leading term is exact for deterministic linear
landscapes, it is higher order terms that quantify the effects of noise and
curvature.
%
It may seem that for small $\eta$ we may neglect higher $O(\eta^d)$ terms.
However, the latter have coefficients that scale like $T^d/d!$, since such
terms intuitively represent the joint effect of the ${T\choose d}$ many
size-$d$ subsets of the %length-$T$
update sequence.   We thus need higher order
terms to analyze SGD for small but finite values of $\eta T$.  

%%  {\color{red}HOW HIGHER ORDER TERMS MATTER: explosion of terms with $T$.
%%simplest nontrivial term?} 

  A Taylor series analysis of SGD presents three challenges.
%
\emph{First}, the terms explode in variety.  The sub-leading terms
represent the diverse ways that some past update may affect a future
weight $\theta_t$ and thus a future update involving $\nabla
l_{x_t}(\theta_t)$.  That is, updates \textbf{interact}.
%
\emph{Second}, SGD's gradient noise is correlated between timesteps: the same
training sample reappears in each epoch.  Such \textbf{finite-sample} effects
complicate inductive analyses because one's induction hypothesis must keep
track of joint moments.%the simple induction-on-$T$ that led to $-T G\eta G$.
%
\emph{Third}, the series' $d$th order truncation \textbf{diverges} as $T$
grows.  E.g.\ for linear least squares, the loss
grows exponentially with time for $\eta<0$; so on no neighorhood of $\eta=0$
does a $d$th Taylor truncation suffer an error uniform in $T$. 

  To address the three challenges, we exploit a graphical representation of
Taylor terms.  These \textbf{diagrams} naturally reflect the combinatorics of
interactions and correlations.
%; each diagram helps to evaluate many terms at once.
Diagrams thus enable the book-keeping necessary to uncover the subtle
phenomena expressed in higher order terms. 

  More formally, each $d$-edged diagram represents multiple $O(\eta^d)$ terms
in the Taylor series.  For instance, a single diagram gives all the leading
order terms.  Though the latter's sum is $O(\eta)$, it diverges as $T$ grows
(c.f. Prop \ref{prop:nest}), intuitively because it does not detect that
learning slows after many updates.  Such divergences plague higher terms, too.
%
In our key technical contribution, we cancel each diagram's divergence against
those of larger, \emph{topologically-related} diagrams.  The graphical notation makes
plain which terms cancel when grouped and what each group's remaining sum is. 
%
These `\textbf{re-summed}' expressions' errors are uniform in $T$ for quadratic
landscapes (with non-Gaussian gradient noise) and are provably finite and
empirically small for convolutional landscapes.


