\BOOKMARK [1][-]{section.0.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.0.2}{Paradigmatic example: a non-conservative entropic force}{}% 2
\BOOKMARK [2][-]{subsection.0.2.1}{Notation and assumptions, I}{section.0.2}% 3
\BOOKMARK [2][-]{subsection.0.2.2}{Taylor series: method and challenges}{section.0.2}% 4
\BOOKMARK [3][-]{subsubsection.0.2.2.1}{What happens when we keep higher order terms?}{subsection.0.2.2}% 5
\BOOKMARK [3][-]{subsubsection.0.2.2.2}{Diagrams in brief}{subsection.0.2.2}% 6
\BOOKMARK [2][-]{subsection.0.2.3}{An entropic force with curl}{section.0.2}% 7
\BOOKMARK [1][-]{section.0.3}{Perturbative theory of SGD}{}% 8
\BOOKMARK [2][-]{subsection.0.3.1}{Notation and assumptions, II}{section.0.3}% 9
\BOOKMARK [2][-]{subsection.0.3.2}{Diagrams arise from Taylor series and depict information-flow processes}{section.0.3}% 10
\BOOKMARK [2][-]{subsection.0.3.3}{Diagrams overcome the challenges of using Taylor series to study SGD}{section.0.3}% 11
\BOOKMARK [3][-]{subsubsection.0.3.3.1}{Resummation}{subsection.0.3.3}% 12
\BOOKMARK [2][-]{subsection.0.3.4}{Main result}{section.0.3}% 13
\BOOKMARK [1][-]{section.0.4}{Consequences of the theory}{}% 14
\BOOKMARK [2][-]{subsection.0.4.1}{Gradient noise repels SGD}{section.0.4}% 15
\BOOKMARK [2][-]{subsection.0.4.2}{SGD and SDE respond differently to changes in curvature}{section.0.4}% 16
\BOOKMARK [2][-]{subsection.0.4.3}{SGD descends on a landscape smoothed by the current C \204 See \2472.3.}{section.0.4}% 17
\BOOKMARK [2][-]{subsection.0.4.4}{Both flat and sharp minima overfit less}{section.0.4}% 18
\BOOKMARK [1][-]{section.0.5}{Experiments}{}% 19
\BOOKMARK [2][-]{subsection.0.5.1}{Training time, epochs, and batch size; C repels SGD more than GD}{section.0.5}% 20
\BOOKMARK [2][-]{subsection.0.5.2}{Sharp and flat minima both overfit less than medium minima}{section.0.5}% 21
\BOOKMARK [1][-]{section.0.6}{Conclusion}{}% 22
\BOOKMARK [2][-]{subsection.0.6.1}{Related work}{section.0.6}% 23
\BOOKMARK [1][-]{section.0.A}{Tutorial: how to use diagrams}{}% 24
\BOOKMARK [2][-]{subsection.0.A.1}{Two example calculations}{section.0.A}% 25
\BOOKMARK [3][-]{subsubsection.0.A.1.1}{Computations: Grids}{subsection.0.A.1}% 26
\BOOKMARK [3][-]{subsubsection.0.A.1.2}{Computations: Embeddings of diagrams into grids}{subsection.0.A.1}% 27
\BOOKMARK [3][-]{subsubsection.0.A.1.3}{Computations: Evaluating each diagram embedding}{subsection.0.A.1}% 28
\BOOKMARK [3][-]{subsubsection.0.A.1.4}{Computations: Summing the embeddings' values}{subsection.0.A.1}% 29
\BOOKMARK [2][-]{subsection.0.A.2}{How to identify the relevant grid}{section.0.A}% 30
\BOOKMARK [2][-]{subsection.0.A.3}{How to identify the relevant diagram embeddings}{section.0.A}% 31
\BOOKMARK [2][-]{subsection.0.A.4}{How to evaluate each embedding}{section.0.A}% 32
\BOOKMARK [3][-]{subsubsection.0.A.4.1}{Un-resummed values: uvalue\(D\)}{subsection.0.A.4}% 33
\BOOKMARK [3][-]{subsubsection.0.A.4.2}{Resummed values: rvaluef\(D\)}{subsection.0.A.4}% 34
\BOOKMARK [3][-]{subsubsection.0.A.4.3}{Overall}{subsection.0.A.4}% 35
\BOOKMARK [2][-]{subsection.0.A.5}{How to sum the embeddings' values}{section.0.A}% 36
\BOOKMARK [2][-]{subsection.0.A.6}{How to solve variant problems}{section.0.A}% 37
\BOOKMARK [2][-]{subsection.0.A.7}{Do diagrams streamline computation?}{section.0.A}% 38
\BOOKMARK [3][-]{subsubsection.0.A.7.1}{Effect of batch size}{subsection.0.A.7}% 39
\BOOKMARK [3][-]{subsubsection.0.A.7.2}{Effect of non-Gaussian noise at a minimum.}{subsection.0.A.7}% 40
\BOOKMARK [1][-]{section.0.B}{Mathematics of the theory}{}% 41
\BOOKMARK [2][-]{subsection.0.B.1}{Assumptions and Definitions}{section.0.B}% 42
\BOOKMARK [2][-]{subsection.0.B.2}{A key lemma \340 la Dyson}{section.0.B}% 43
\BOOKMARK [2][-]{subsection.0.B.3}{From Dyson to diagrams}{section.0.B}% 44
\BOOKMARK [2][-]{subsection.0.B.4}{Proof of Theorem 1}{section.0.B}% 45
\BOOKMARK [2][-]{subsection.0.B.5}{Proof of Theorem 2}{section.0.B}% 46
\BOOKMARK [2][-]{subsection.0.B.6}{Proofs of corollaries}{section.0.B}% 47
\BOOKMARK [3][-]{subsubsection.0.B.6.1}{Corollary 1}{subsection.0.B.6}% 48
\BOOKMARK [3][-]{subsubsection.0.B.6.2}{Corollary 5's first part}{subsection.0.B.6}% 49
\BOOKMARK [3][-]{subsubsection.0.B.6.3}{Corollary 5's second part}{subsection.0.B.6}% 50
\BOOKMARK [3][-]{subsubsection.0.B.6.4}{Corollaries 3 and 2}{subsection.0.B.6}% 51
\BOOKMARK [3][-]{subsubsection.0.B.6.5}{Corollary 4}{subsection.0.B.6}% 52
\BOOKMARK [2][-]{subsection.0.B.7}{Future topics}{section.0.B}% 53
\BOOKMARK [1][-]{section.0.C}{Experimental methods}{}% 54
\BOOKMARK [2][-]{subsection.0.C.1}{What artificial landscapes did we use?}{section.0.C}% 55
\BOOKMARK [3][-]{subsubsection.0.C.1.1}{Gauss}{subsection.0.C.1}% 56
\BOOKMARK [3][-]{subsubsection.0.C.1.2}{Helix}{subsection.0.C.1}% 57
\BOOKMARK [3][-]{subsubsection.0.C.1.3}{Mean Estimation}{subsection.0.C.1}% 58
\BOOKMARK [2][-]{subsection.0.C.2}{What image-classification landscapes did we use?}{section.0.C}% 59
\BOOKMARK [3][-]{subsubsection.0.C.2.1}{Architectures}{subsection.0.C.2}% 60
\BOOKMARK [3][-]{subsubsection.0.C.2.2}{Datasets}{subsection.0.C.2}% 61
\BOOKMARK [2][-]{subsection.0.C.3}{Measurement process}{section.0.C}% 62
\BOOKMARK [3][-]{subsubsection.0.C.3.1}{Diagram evaluation on real landscapes}{subsection.0.C.3}% 63
\BOOKMARK [3][-]{subsubsection.0.C.3.2}{Descent simulations}{subsection.0.C.3}% 64
\BOOKMARK [2][-]{subsection.0.C.4}{Implementing optimizers}{section.0.C}% 65
\BOOKMARK [2][-]{subsection.0.C.5}{Software frameworks and hardware}{section.0.C}% 66
\BOOKMARK [2][-]{subsection.0.C.6}{Unbiased estimators of landscape statistics}{section.0.C}% 67
\BOOKMARK [2][-]{subsection.0.C.7}{Additional figures}{section.0.C}% 68
\BOOKMARK [1][-]{section.0.D}{Review of Tensors}{}% 69
\BOOKMARK [2][-]{subsection.0.D.1}{What is a tensor?}{section.0.D}% 70
\BOOKMARK [2][-]{subsection.0.D.2}{Vectors versus covectors}{section.0.D}% 71
\BOOKMARK [2][-]{subsection.0.D.3}{Contraction}{section.0.D}% 72
\BOOKMARK [2][-]{subsection.0.D.4}{Linear maps as tensors}{section.0.D}% 73
